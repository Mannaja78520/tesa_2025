from sahi import AutoDetectionModel
from sahi.predict import get_sliced_prediction
import cv2
import os

# ---------- CONFIG ----------
DRONE_MODEL_PATH = "drone.pt"
TEST_DIR = "P1_DATASET/TEST_DATA"
SAVE_DIR = "P1_DATASET/TEST_RESULTS_SAHI"

DRONE_CLASS_NAME = "drone"
MAX_DRONES = 2

CONF_THRESH = 0.275
CONF_UNDER_LINE_THRESH = 0.70

# SAHI slice ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£
SLICE_W = 300
SLICE_H = 300
OVERLAP = 0.2

# ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏Å‡πà‡∏≠‡∏ô detect (‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÇ‡∏î‡∏£‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡πá‡∏Å‡∏î‡∏π‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏∂‡πâ‡∏ô)
ZOOM = 5.0          # ‡∏•‡∏≠‡∏á 1.5, 2.0, 3.0 ‡πÑ‡∏î‡πâ ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÑ‡∏´‡∏ß

AUTO_DELAY_MS = 500

GROUND_RATIO = 0.65       # ‡πÄ‡∏™‡πâ‡∏ô ground line (0.0 = ‡∏ö‡∏ô‡∏™‡∏∏‡∏î, 1.0 = ‡∏•‡πà‡∏≤‡∏á‡∏™‡∏∏‡∏î)
BIG_OBJ_RATIO = 0.0     # ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏π‡πà‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ ground_line ‡πÅ‡∏•‡∏∞ area > ratio ‡∏ô‡∏µ‡πâ => ‡∏°‡∏≠‡∏á‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô stadium/‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ

# ‡∏ü‡∏¥‡∏•‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Ç‡∏ô‡∏≤‡∏î‡∏Å‡∏•‡πà‡∏≠‡∏á (‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏†‡∏≤‡∏û‡∏à‡∏£‡∏¥‡∏á)
MIN_RATIO = 0.0      # ‡πÄ‡∏•‡πá‡∏Å‡∏™‡∏∏‡∏î (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏î‡∏£‡∏ô‡∏à‡∏¥‡πã‡∏ß)
MAX_RATIO = 1.0      # ‡πÉ‡∏´‡∏ç‡πà‡∏™‡∏∏‡∏î
# -----------------------------

os.makedirs(SAVE_DIR, exist_ok=True)

# ----- ‡∏™‡∏£‡πâ‡∏≤‡∏á SAHI detection model -----
detection_model = AutoDetectionModel.from_pretrained(
    model_type="ultralytics",        # ‡πÉ‡∏ä‡πâ Ultralytics YOLO (v8/11)
    model_path=DRONE_MODEL_PATH,
    confidence_threshold=CONF_THRESH,
    device="cpu",
)

print("‚úÖ SAHI + YOLO model ready")

# ----- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î -----
print("\n=== ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô ===")
print("1: ‡πÄ‡∏ã‡∏ü‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏∏‡∏Å‡∏†‡∏≤‡∏û + ‡πÇ‡∏ä‡∏ß‡πå + ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (Save All)")
print("2: ‡∏î‡∏π‡∏ó‡∏µ‡∏•‡∏∞‡∏†‡∏≤‡∏û ‡πÑ‡∏°‡πà‡πÄ‡∏ã‡∏ü (View Only)")
mode = input("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î (1/2): ").strip()
save_all = (mode == "1")

if save_all:
    print(f"üíæ ‡πÇ‡∏´‡∏°‡∏î 1: ‡πÄ‡∏ã‡∏ü‡∏ó‡∏∏‡∏Å‡∏†‡∏≤‡∏û‡∏•‡∏á‡πÉ‡∏ô {SAVE_DIR}\n")
else:
    print("üëÅÔ∏è ‡πÇ‡∏´‡∏°‡∏î 2: ‡∏î‡∏π‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÑ‡∏°‡πà‡πÄ‡∏ã‡∏ü‡πÑ‡∏ü‡∏•‡πå\n")

# ----- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏£‡∏π‡∏õ -----
image_files = sorted(
    f for f in os.listdir(TEST_DIR)
    if f.lower().endswith((".jpg", ".jpeg", ".png"))
)

for i, filename in enumerate(image_files, 1):
    img_path = os.path.join(TEST_DIR, filename)
    img = cv2.imread(img_path)
    if img is None:
        print(f"‡∏Ç‡πâ‡∏≤‡∏° {filename} (‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏π‡∏õ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à)")
        continue

    H, W = img.shape[:2]
    img_area = H * W
    ground_line = int(H * GROUND_RATIO)

     # ===== 1) ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏Å‡πà‡∏≠‡∏ô detect =====
    img_zoom = cv2.resize(
        img, None, fx=ZOOM, fy=ZOOM,
        interpolation=cv2.INTER_LINEAR
    )

    # ----- SAHI + YOLO slicing inference -----
    result = get_sliced_prediction(
        image=img_zoom,
        detection_model=detection_model,
        slice_height=int(SLICE_H * ZOOM),   # slice ‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ã‡∏π‡∏°‡πÅ‡∏•‡πâ‡∏ß
        slice_width=int(SLICE_W * ZOOM),
        overlap_height_ratio=OVERLAP,
        overlap_width_ratio=OVERLAP,
    )

    drone_candidates = []

    for obj in result.object_prediction_list:
        class_name = obj.category.name
        score = float(obj.score.value)
        if class_name != DRONE_CLASS_NAME:
            continue

        # ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏≠‡∏¢‡∏π‡πà‡∏ö‡∏ô‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ã‡∏π‡∏° -> ‡∏´‡∏≤‡∏£‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏û‡∏à‡∏£‡∏¥‡∏á‡∏Å‡πà‡∏≠‡∏ô
        zx1, zy1, zx2, zy2 = obj.bbox.to_xyxy()
        x1 = int(zx1 / ZOOM)
        y1 = int(zy1 / ZOOM)
        x2 = int(zx2 / ZOOM)
        y2 = int(zy2 / ZOOM)

        # ‡∏Ñ‡∏•‡∏µ‡∏ô‡∏Ç‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏†‡∏≤‡∏û
        x1 = max(0, min(W - 1, x1))
        x2 = max(0, min(W - 1, x2))
        y1 = max(0, min(H - 1, y1))
        y2 = max(0, min(H - 1, y2))

        w = x2 - x1
        h = y2 - y1
        if w <= 0 or h <= 0:
            continue

        cx = (x1 + x2) // 2
        cy = (y1 + y2) // 2

        # ---------- 1) ‡∏ü‡∏¥‡∏•‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Ç‡∏ô‡∏≤‡∏î‡∏Å‡∏•‡πà‡∏≠‡∏á ----------
        box_area = w * h
        if not (MIN_RATIO * img_area <= box_area <= MAX_RATIO * img_area):
            continue

        # ---------- 2) ground line ‡πÅ‡∏ö‡∏ö‡∏ô‡∏¥‡πà‡∏° ----------
        # ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏π‡πà‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ ground_line ‡πÅ‡∏•‡∏∞ "‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô" -> ‡∏°‡∏≠‡∏á‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô stadium/‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ -> ‡∏ó‡∏¥‡πâ‡∏á
        if (cy > ground_line) and (box_area > BIG_OBJ_RATIO * img_area):
            if (score < CONF_UNDER_LINE_THRESH):
                continue
        # ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏π‡πà‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ ground_line ‡πÅ‡∏ï‡πà‡πÄ‡∏•‡πá‡∏Å‡∏°‡∏≤‡∏Å -> ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏î‡∏£‡∏ô‡∏ó‡∏µ‡πà‡∏ö‡∏¥‡∏ô‡∏ï‡πà‡∏≥ -> ‡πÉ‡∏´‡πâ‡∏ú‡πà‡∏≤‡∏ô

        # ---------- 3) ‡∏£‡∏π‡∏õ‡∏ó‡∏£‡∏á: ‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÅ‡∏ô‡∏ß‡∏ô‡∏≠‡∏ô / ‡∏à‡∏±‡∏ï‡∏∏‡∏£‡∏±‡∏™ ----------
        aspect = w / float(h)
        if aspect < 0.8:   # ‡∏ú‡πà‡∏≠‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°‡∏´‡∏ô‡πà‡∏≠‡∏¢ ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏°‡∏∏‡∏°‡πÄ‡∏≠‡∏µ‡∏¢‡∏á
            continue
        aspect = h / float(w)
        if aspect < 0.65:   # ‡∏ú‡πà‡∏≠‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°‡∏´‡∏ô‡πà‡∏≠‡∏¢ ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏°‡∏∏‡∏°‡πÄ‡∏≠‡∏µ‡∏¢‡∏á
            continue

        drone_candidates.append((score, x1, y1, x2, y2, cx, cy))

    # ----- ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 2 ‡∏•‡∏≥ -----
    drone_candidates.sort(key=lambda d: d[0], reverse=True)
    drone_candidates = drone_candidates[:MAX_DRONES]

    # ----- ‡∏ß‡∏≤‡∏î‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏ö‡∏ô‡∏†‡∏≤‡∏û‡∏à‡∏£‡∏¥‡∏á -----
    for score, x1, y1, x2, y2, cx, cy in drone_candidates:
        label = f"{DRONE_CLASS_NAME} {score:.2f}"
        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(img, label, (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        print(f"[{i}/{len(image_files)}] {filename} -> {label} center=({cx},{cy})")

    # ----- ‡πÄ‡∏ã‡∏ü‡∏ñ‡πâ‡∏≤‡πÇ‡∏´‡∏°‡∏î save_all -----
    if save_all:
        save_path = os.path.join(SAVE_DIR, filename)
        cv2.imwrite(save_path, img)
        print(f"üíæ Saved: {save_path}")

    # ----- ‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û -----
    cv2.line(img, (0, ground_line), (W-1, ground_line), (0, 0, 255), 2)
    img_disp = cv2.resize(img, (720, 480))
    cv2.imshow("Detect_Image", img_disp)

    if save_all:
        key = cv2.waitKey(AUTO_DELAY_MS) & 0xFF
        if key in [ord("q"), 27]:
            break
    else:
        print("‚û°Ô∏è  Space/Enter = ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ, q = ‡∏≠‡∏≠‡∏Å")
        key = cv2.waitKey(0) & 0xFF
        if key in [ord("q"), 27]:
            break

cv2.destroyAllWindows()
print("‚úÖ SAHI + YOLO (ZOOM + ground line soft) ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")